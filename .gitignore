!pip install -U torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
import torch
import torch.nn as nn
import torch.optim as optim

# ==============================
# 🔹 Lower-level objective
# ==============================
def lower_objective(patients_in_hospital, consult_time, assign_time, n_beds):
    n_patients = len(patients_in_hospital)
    if n_patients == 0:
        return 0
    base_time = (consult_time + assign_time) * n_patients
    penalty = max(0, (n_patients - n_beds) * (consult_time + assign_time) * 2)
    return base_time + penalty

# ==============================
# 🔹 Bilevel objective
# ==============================
def bilevel_objective(solution, travel, waiting, consult, assign, beds):
    solution = solution.astype(int)
    total_time = 0
    for i, hospital_idx in enumerate(solution):
        total_time += travel[i, hospital_idx] + waiting[hospital_idx]
    for h in range(len(beds)):
        patients_h = [i for i, s in enumerate(solution) if s == h]
        total_time += lower_objective(patients_h, consult[h], assign[h], beds[h])
    return total_time

# ==============================
# 🔹 DQN RL Agent
# ==============================
class DQN(nn.Module):
    def __init__(self, n_patients, n_hospitals, hidden=128):
        super().__init__()
        self.n_patients = n_patients
        self.n_hospitals = n_hospitals
        self.fc = nn.Sequential(
            nn.Linear(n_patients * n_hospitals, hidden),
            nn.ReLU(),
            nn.Linear(hidden, n_patients * n_hospitals)
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        out = self.fc(x)
        return out.view(-1, self.n_patients, self.n_hospitals)

class DQNAgent:
    def __init__(self, n_patients, n_hospitals, lr=0.001, gamma=0.9, epsilon=0.2):
        self.n_patients = n_patients
        self.n_hospitals = n_hospitals
        self.gamma = gamma
        self.epsilon = epsilon
        self.model = DQN(n_patients, n_hospitals)
        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)
        self.loss_fn = nn.MSELoss()

    def select_action(self, state):
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        if np.random.rand() < self.epsilon:
            return np.random.randint(self.n_hospitals, size=self.n_patients)
        with torch.no_grad():
            q_values = self.model(state_tensor).squeeze(0).numpy()
            return np.argmax(q_values, axis=1)

    def train(self, state, action, reward, next_state):
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0)
        q_pred = self.model(state_tensor)
        q_target = q_pred.clone().detach()
        for i in range(self.n_patients):
            q_target[0, i, action[i]] = reward[i] + self.gamma * torch.max(self.model(next_state_tensor)[0, i]).item()
        loss = self.loss_fn(q_pred, q_target)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

# ==============================
# 🔹 Run RL for one period
# ==============================
def run_dqn_rl(n_patients, n_hospitals, travel, waiting, consult, assign, beds, epochs=200):
    state = np.zeros((n_patients, n_hospitals))
    agent = DQNAgent(n_patients, n_hospitals)
    max_possible_time = n_patients * (np.max(travel) + np.max(waiting) + np.max(consult) + np.max(assign))
    
    for ep in range(epochs):
        action = agent.select_action(state)
        solution = np.array(action)
        reward_value = (max_possible_time - bilevel_objective(solution, travel, waiting, consult, assign, beds)) / max_possible_time
        reward = np.full(n_patients, reward_value)
        agent.epsilon = max(0.05, 0.2 * (0.995 ** ep))
        next_state = np.zeros((n_patients, n_hospitals))
        for i, a in enumerate(action):
            next_state[i, a] = 1
        agent.train(state, action, reward, next_state)
        state = next_state
    
    best_solution = agent.select_action(state)
    best_fit = bilevel_objective(best_solution, travel, waiting, consult, assign, beds)
    return best_solution, best_fit

# ==============================
# 🔹 Dynamic periods
# ==============================
n_periods = 5
patients_init = 200
hospitals_init = 5
patient_growth = 0.05
hospital_growth = 0.02
patients_list, hospitals_list = [], []
p, h = patients_init, hospitals_init
for _ in range(n_periods):
    p = max(1, int(p * (1 + patient_growth + np.random.normal(0, 0.02))))
    h = max(1, int(h * (1 + hospital_growth + np.random.normal(0, 0.01))))
    patients_list.append(p)
    hospitals_list.append(h)

# ==============================
# 🔹 Data generation
# ==============================
def generate_times(n_patients, n_hospitals):
    travel = np.random.randint(5, 60, size=(n_patients, n_hospitals))
    waiting = np.random.randint(10, 120, size=n_hospitals)
    consult = np.random.randint(15, 30, size=n_hospitals)
    assign = np.random.randint(5, 30, size=n_hospitals)
    beds = np.random.randint(10, 50, size=n_hospitals)
    return travel, waiting, consult, assign, beds

# ==============================
# 🔹 Main loop RL-only
# ==============================
results = []
for period in range(n_periods):
    n_patients = patients_list[period]
    n_hospitals = hospitals_list[period]
    travel, waiting, consult, assign, beds = generate_times(n_patients, n_hospitals)
    
    print(f"\n🗓️ Period {period+1}: {n_patients} patients, {n_hospitals} hospitals")
    
    start = time.time()
    best_solution, best_fit = run_dqn_rl(n_patients, n_hospitals, travel, waiting, consult, assign, beds, epochs=200)
    duration = time.time() - start
    print(f"  RL-DQN => Best total time: {best_fit:.2f} min | Duration: {duration:.2f} s")
    
    results.append({
        "Period": period + 1,
        "Patients": n_patients,
        "Hospitals": n_hospitals,
        "BestTime": best_fit,
        "Duration": duration
    })

# ==============================
# 🔹 Visualization
# ==============================
df_results = pd.DataFrame(results)
plt.figure(figsize=(12, 6))
plt.plot(df_results["Period"], df_results["BestTime"], marker='o', label="RL-DQN")
plt.title("Bilevel Optimal Total Time per Period (RL Only)")
plt.xlabel("Period")
plt.ylabel("Total time (minutes)")
plt.legend()
plt.grid(True)
plt.show()
